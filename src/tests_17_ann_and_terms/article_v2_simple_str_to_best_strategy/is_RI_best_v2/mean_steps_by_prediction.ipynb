{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:53:37.318473500Z",
     "start_time": "2023-12-01T15:53:17.234782900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\voldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\voldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Conv1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertConfig\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from calculus_path_mod.terms.pseudonym import *\n",
    "from calculus_path_mod.reduction_strategy import *\n",
    "from calculus_path_mod.terms.arithm_complex_ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sequence_len = 512\n",
    "batch_size = 64\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=9,\n",
    "    hidden_size=84,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=6,\n",
    "    intermediate_size=64,\n",
    "    max_position_embeddings=sequence_len,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load & Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all terms: 4251\n",
      "\n",
      "Count original terms: 4251\n",
      "\n",
      "number samples: 4251\n",
      "number samples only reducable: 4220\n",
      "\n",
      "max RI steps count: 386\n",
      "max LO steps count: 219\n",
      "Count TESTING samples: 4220\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../article_models_reduct_steps_by_simple_str/data_steps/steps_simple_term_str.csv\", delimiter=',')\n",
    "\n",
    "# leave only unique terms\n",
    "print(f\"Count all terms: {len(all_data)}\\n\")\n",
    "all_data = all_data.drop_duplicates(subset=\"simple_terms\").reset_index(drop=True)\n",
    "print(f\"Count original terms: {len(all_data)}\\n\")\n",
    "\n",
    "# shuffle the dataset\n",
    "# all_data = shuffle(all_data, random_state=33).reset_index(drop=True)\n",
    "all_data = all_data.drop_duplicates([\"simple_terms\"])\n",
    "\n",
    "# drop unreducable by LO or RI\n",
    "print(f\"number samples: {len(all_data)}\")\n",
    "all_data = all_data[[x_ != 1000 for x_ in all_data[\"RI_steps_num\"]]].reset_index(drop=True)\n",
    "all_data = all_data[[x_ != 1000 for x_ in all_data[\"LO_steps_num\"]]].reset_index(drop=True)\n",
    "print(f\"number samples only reducable: {len(all_data)}\\n\")\n",
    "\n",
    "print(f\"max RI steps count: {max(all_data['RI_steps_num'])}\")\n",
    "print(f\"max LO steps count: {max(all_data['LO_steps_num'])}\")\n",
    "\n",
    "x_test = all_data[\"simple_terms\"].tolist()\n",
    "# RI has fewer steps -> 1\n",
    "# Otherwise 0\n",
    "y_test = [1 if los > ris else 0 for los, ris in zip(all_data[\"LO_steps_num\"].tolist(), all_data[\"RI_steps_num\"].tolist())]\n",
    "y_ri_test = all_data[\"LO_steps_num\"].tolist()\n",
    "y_lo_test = all_data[\"RI_steps_num\"].tolist()\n",
    "\n",
    "print(f\"Count TESTING samples: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all terms: 44568\n",
      "\n",
      "Count original terms: 44568\n",
      "\n",
      "number samples: 44568\n",
      "number samples only reducable: 42469\n",
      "\n",
      "max RI steps count: 400\n",
      "max LO steps count: 308\n",
      "Count TRAINING samples: 42469\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../article_models_reduct_steps_by_simple_str/data_steps/steps_simple_term_str_extended.csv\", delimiter=',')\n",
    "\n",
    "# leave only unique terms\n",
    "print(f\"Count all terms: {len(all_data)}\\n\")\n",
    "all_data = all_data.drop_duplicates(subset=\"simple_terms\").reset_index(drop=True)\n",
    "print(f\"Count original terms: {len(all_data)}\\n\")\n",
    "\n",
    "# shuffle the dataset\n",
    "# all_data = shuffle(all_data, random_state=33).reset_index(drop=True)\n",
    "all_data = all_data.drop_duplicates([\"simple_terms\"])\n",
    "\n",
    "# drop unreducable by LO or RI\n",
    "print(f\"number samples: {len(all_data)}\")\n",
    "all_data = all_data[[x_ != 1000 for x_ in all_data[\"RI_steps_num\"]]].reset_index(drop=True)\n",
    "all_data = all_data[[x_ != 1000 for x_ in all_data[\"LO_steps_num\"]]].reset_index(drop=True)\n",
    "print(f\"number samples only reducable: {len(all_data)}\\n\")\n",
    "\n",
    "print(f\"max RI steps count: {max(all_data['RI_steps_num'])}\")\n",
    "print(f\"max LO steps count: {max(all_data['LO_steps_num'])}\")\n",
    "\n",
    "x_train = all_data[\"simple_terms\"].tolist()\n",
    "# RI has fewer steps -> 1\n",
    "# Otherwise 0\n",
    "y_train = [1 if los > ris else 0 for los, ris in zip(all_data[\"LO_steps_num\"].tolist(), all_data[\"RI_steps_num\"].tolist())]\n",
    "y_ri_train = all_data[\"LO_steps_num\"].tolist()\n",
    "y_lo_train = all_data[\"RI_steps_num\"].tolist()\n",
    "\n",
    "print(f\"Count TRAINING samples: {len(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"../../transformers_to_lo_steps_prediciton/fine_models\", max_len=sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = [x_.replace(\"@x.\", \"y\").replace(\" \", \"\") for x_ in x_train]\n",
    "x_test = [x_.replace(\"@x.\", \"y\").replace(\" \", \"\") for x_ in x_test]\n",
    "\n",
    "train_df = pd.DataFrame({\"term_str\": x_train, \"is_ri_best\": y_train})\n",
    "test_df = pd.DataFrame({\"term_str\": x_test, \"is_ri_best\": y_test})\n",
    "\n",
    "def preprocess(example):\n",
    "    # Tokenize the prompt\n",
    "    tokenized_texts = tokenizer(example['term_str'].to_list(), truncation=True, padding='max_length', max_length=sequence_len, return_tensors=\"tf\")\n",
    "    labels = tf.convert_to_tensor(example[\"is_ri_best\"])\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "\n",
    "tokenized_train_data = preprocess(train_df)\n",
    "tokenized_test_data = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(tokenized_train_data[0]), tokenized_train_data[1])).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(tokenized_test_data[0]), tokenized_test_data[1])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual_labels, predicted_labels):\n",
    "    correct_predictions = sum(1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == predicted)\n",
    "    total_predictions = len(actual_labels)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, class_labels, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix of a classification model.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): The ground truth labels.\n",
    "        y_pred (numpy.ndarray): The predicted labels.\n",
    "        classes (list): The list of class labels.\n",
    "        class_labels: The list of class names.\n",
    "        normalize (bool, optional): Whether to normalize the confusion matrix. Defaults to False.\n",
    "        title (str, optional): The title of the plot. Defaults to None.\n",
    "        cmap (matplotlib.colors.Colormap, optional): The colormap to use for the plot. Defaults to plt.cm.Blues.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=classes).astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(class_labels)\n",
    "    ax.set_yticklabels(class_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            ij = float(cm[i, j])\n",
    "            ax.text(j, i, f\"{ij:.2f}\", ha='center', va='center', color='white' if ij > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# The best & worst possible steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Test WORST steps: avg=23.878, sum=100764\n",
      "Train WORST steps: avg=24.455, sum=1038575\n",
      "\n",
      "Test WORST LO steps: avg=22.375, sum=94422\n",
      "Train WORST LO steps: avg=22.175, sum=941755\n",
      "\n",
      "Test WORST RI steps: avg=16.753, sum=70698\n",
      "Train WORST RI steps: avg=15.590, sum=662085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_best_sum = 0\n",
    "for lo_, ri_ in zip(y_lo_test, y_ri_test):\n",
    "    y_test_best_sum += lo_ if lo_ <= ri_ else ri_\n",
    "y_test_best_avg = y_test_best_sum / len(y_lo_test)\n",
    "\n",
    "y_train_best_sum = 0\n",
    "for lo_, ri_ in zip(y_lo_train, y_ri_train):\n",
    "    y_train_best_sum += lo_ if lo_ <= ri_ else ri_\n",
    "y_train_best_avg = y_train_best_sum / len(y_lo_train)\n",
    "\n",
    "\n",
    "y_test_worst_sum = 0\n",
    "for lo_, ri_ in zip(y_lo_test, y_ri_test):\n",
    "    y_test_worst_sum += lo_ if lo_ > ri_ else ri_\n",
    "y_test_worst_avg = y_test_worst_sum / len(y_lo_test)\n",
    "\n",
    "y_train_worst_sum = 0\n",
    "for lo_, ri_ in zip(y_lo_train, y_ri_train):\n",
    "    y_train_worst_sum += lo_ if lo_ > ri_ else ri_\n",
    "y_train_worst_avg = y_train_worst_sum / len(y_lo_train)\n",
    "\n",
    "\n",
    "y_test_worst_LO_sum = np.sum(y_lo_test)\n",
    "y_test_worst_LO_avg = np.mean(y_lo_test)\n",
    "\n",
    "y_train_worst_LO_sum = np.sum(y_lo_train)\n",
    "y_train_worst_LO_avg = np.mean(y_lo_train)\n",
    "\n",
    "\n",
    "y_test_worst_RI_sum = np.sum(y_ri_test)\n",
    "y_test_worst_RI_avg = np.mean(y_ri_test)\n",
    "\n",
    "y_train_worst_RI_sum = np.sum(y_ri_train)\n",
    "y_train_worst_RI_avg = np.mean(y_ri_train)\n",
    "\n",
    "\n",
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Test WORST steps: avg={y_test_worst_avg:.3f}, sum={y_test_worst_sum}\")\n",
    "print(f\"Train WORST steps: avg={y_train_worst_avg:.3f}, sum={y_train_worst_sum}\\n\")\n",
    "\n",
    "print(f\"Test WORST LO steps: avg={y_test_worst_LO_avg:.3f}, sum={y_test_worst_LO_sum}\")\n",
    "print(f\"Train WORST LO steps: avg={y_train_worst_LO_avg:.3f}, sum={y_train_worst_LO_sum}\\n\")\n",
    "\n",
    "print(f\"Test WORST RI steps: avg={y_test_worst_RI_avg:.3f}, sum={y_test_worst_RI_sum}\")\n",
    "print(f\"Train WORST RI steps: avg={y_train_worst_RI_avg:.3f}, sum={y_train_worst_RI_sum}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_steps_accuracy(y_predictions, y_lo_steps, y_ri_steps, threshold=0.5):\n",
    "    y_steps_sum = 0\n",
    "    for lo_, ri_, pred_ in zip(y_lo_steps, y_ri_steps, y_predictions):\n",
    "        y_steps_sum += lo_ if pred_ < threshold else ri_\n",
    "    y_steps_avg = y_steps_sum / len(y_lo_steps)\n",
    "    return y_steps_sum, y_steps_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 160 epochs trained model on all terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T15:56:20.076064Z",
     "start_time": "2023-11-28T15:55:25.881953Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 74ms/step\n",
      "664/664 [==============================] - 46s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:25:08.234149Z",
     "start_time": "2023-11-28T16:25:07.937015Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 160ep, 0.5th\n",
      "Test steps: avg=22.072, sum=93142\n",
      "Train steps: avg=23.953, sum=1017261\n",
      "\n",
      "Models results 160ep, 0.35th\n",
      "Test steps: avg=21.980, sum=92754\n",
      "Train steps: avg=23.990, sum=1018851\n",
      "\n",
      "Models results 160ep, 0.15th\n",
      "Test steps: avg=21.522, sum=90824\n",
      "Train steps: avg=23.865, sum=1013519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep, 0.5th\")\n",
    "y_test_sum_160_05, y_test_avg_160_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_160_05, y_train_avg_160_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_160_05:.3f}, sum={y_test_sum_160_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_05:.3f}, sum={y_train_sum_160_05}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep, 0.35th\")\n",
    "y_test_sum_160_035, y_test_avg_160_035 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_160_035, y_train_avg_160_035 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_160_035:.3f}, sum={y_test_sum_160_035}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_035:.3f}, sum={y_train_sum_160_035}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep, 0.15th\")\n",
    "y_test_sum_160_015, y_test_avg_160_015 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_160_015, y_train_avg_160_015 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_160_015:.3f}, sum={y_test_sum_160_015}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_015:.3f}, sum={y_train_sum_160_015}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 160 epochs trained, best f1 model on all terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:26:53.897620Z",
     "start_time": "2023-11-28T16:26:01.477246Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 70ms/step\n",
      "664/664 [==============================] - 46s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:28:08.308553Z",
     "start_time": "2023-11-28T16:28:08.027928Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 160ep f1, 0.5th\n",
      "Test steps: avg=22.173, sum=93570\n",
      "Train steps: avg=23.591, sum=1001904\n",
      "\n",
      "Models results 160ep f1, 0.35th\n",
      "Test steps: avg=21.850, sum=92205\n",
      "Train steps: avg=23.650, sum=1004392\n",
      "\n",
      "Models results 160ep f1, 0.15th\n",
      "Test steps: avg=21.261, sum=89722\n",
      "Train steps: avg=23.389, sum=993316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep f1, 0.5th\")\n",
    "y_test_sum_160_f1_05, y_test_avg_160_f1_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_160_f1_05, y_train_avg_160_f1_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_160_f1_05:.3f}, sum={y_test_sum_160_f1_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_f1_05:.3f}, sum={y_train_sum_160_f1_05}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep f1, 0.35th\")\n",
    "y_test_sum_160_f1_035, y_test_avg_160_f1_035 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_160_f1_035, y_train_avg_160_f1_035 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_160_f1_035:.3f}, sum={y_test_sum_160_f1_035}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_f1_035:.3f}, sum={y_train_sum_160_f1_035}\\n\")\n",
    "\n",
    "print(f\"Models results 160ep f1, 0.15th\")\n",
    "y_test_sum_160_f1_015, y_test_avg_160_f1_015 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_160_f1_015, y_train_avg_160_f1_015 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_160_f1_015:.3f}, sum={y_test_sum_160_f1_015}\")\n",
    "print(f\"Train steps: avg={y_train_avg_160_f1_015:.3f}, sum={y_train_sum_160_f1_015}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epochs trained model on reducible terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:36:52.224854Z",
     "start_time": "2023-11-28T16:35:59.876619Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 5s 69ms/step\n",
      "664/664 [==============================] - 46s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_only_reducable.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:46:14.406071Z",
     "start_time": "2023-11-28T16:46:14.132844Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, only reducible, 0.5th\n",
      "Test steps: avg=21.961, sum=92676\n",
      "Train steps: avg=23.575, sum=1001201\n",
      "\n",
      "Models results 90ep, only reducible, 0.35th\n",
      "Test steps: avg=21.818, sum=92072\n",
      "Train steps: avg=23.661, sum=1004850\n",
      "\n",
      "Models results 90ep, only reducible, 0.15th\n",
      "Test steps: avg=21.277, sum=89790\n",
      "Train steps: avg=23.558, sum=1000475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.5th\")\n",
    "y_test_sum_90_red_05, y_test_avg_90_red_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_90_red_05, y_train_avg_90_red_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_05:.3f}, sum={y_test_sum_90_red_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_05:.3f}, sum={y_train_sum_90_red_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.35th\")\n",
    "y_test_sum_90_red_035, y_test_avg_90_red_035 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_90_red_035, y_train_avg_90_red_035 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_035:.3f}, sum={y_test_sum_90_red_035}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_035:.3f}, sum={y_train_sum_90_red_035}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.15th\")\n",
    "y_test_sum_90_red_015, y_test_avg_90_red_015 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_90_red_015, y_train_avg_90_red_015 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_015:.3f}, sum={y_test_sum_90_red_015}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_015:.3f}, sum={y_train_sum_90_red_015}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epochs trained best f1 model on reducible terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:58:09.617063Z",
     "start_time": "2023-11-28T16:57:15.999927Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 73ms/step\n",
      "664/664 [==============================] - 46s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_only_reducable.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T16:58:43.931220Z",
     "start_time": "2023-11-28T16:58:43.641126Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, only reducible, 0.5th\n",
      "Test steps: avg=22.058, sum=92676\n",
      "Train steps: avg=23.591, sum=1001201\n",
      "\n",
      "Models results 90ep, only reducible, 0.35th\n",
      "Test steps: avg=21.943, sum=92599\n",
      "Train steps: avg=23.635, sum=1003738\n",
      "\n",
      "Models results 90ep, only reducible, 0.15th\n",
      "Test steps: avg=21.423, sum=90404\n",
      "Train steps: avg=23.409, sum=994177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.5th\")\n",
    "y_test_sum_90_red_f1_05, y_test_avg_90_red_f1_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_90_red_f1_05, y_train_avg_90_red_f1_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_f1_05:.3f}, sum={y_test_sum_90_red_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_f1_05:.3f}, sum={y_train_sum_90_red_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.35th\")\n",
    "y_test_sum_90_red_f1_035, y_test_avg_90_red_f1_035 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_90_red_f1_035, y_train_avg_90_red_f1_035 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_f1_035:.3f}, sum={y_test_sum_90_red_f1_035}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_f1_035:.3f}, sum={y_train_sum_90_red_f1_035}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, only reducible, 0.15th\")\n",
    "y_test_sum_90_red_f1_015, y_test_avg_90_red_f1_015 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_90_red_f1_015, y_train_avg_90_red_f1_015 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_f1_015:.3f}, sum={y_test_sum_90_red_f1_015}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_f1_015:.3f}, sum={y_train_sum_90_red_f1_015}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight\n",
    " sample_weight = (abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps) + mu) + mu), where mu = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:54:18.707478Z",
     "start_time": "2023-11-30T13:53:30.420513Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 51ms/step\n",
      "664/664 [==============================] - 34s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:56:02.339359Z",
     "start_time": "2023-11-30T13:56:02.065269Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted, 0.5th\n",
      "Test steps: avg=21.420, sum=90393\n",
      "Train steps: avg=24.162, sum=1026129\n",
      "\n",
      "Models results 90ep, red weighted, 0.35th\n",
      "Test steps: avg=21.289, sum=89840\n",
      "Train steps: avg=24.163, sum=1026174\n",
      "\n",
      "Models results 90ep, red weighted, 0.15th\n",
      "Test steps: avg=21.007, sum=88648\n",
      "Train steps: avg=24.040, sum=1020935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.5th\")\n",
    "y_test_sum_90_red_w_05, y_test_avg_90_red_w_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_90_red_w_05, y_train_avg_90_red_w_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_w_05:.3f}, sum={y_test_sum_90_red_w_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_w_05:.3f}, sum={y_train_sum_90_red_w_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.35th\")\n",
    "y_test_sum_90_red_w_035, y_test_avg_90_red_w_035 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_90_red_w_035, y_train_avg_90_red_w_035 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_w_035:.3f}, sum={y_test_sum_90_red_w_035}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_w_035:.3f}, sum={y_train_sum_90_red_w_035}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.15th\")\n",
    "y_test_sum_90_red_w_015, y_test_avg_90_red_w_015 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_90_red_w_015, y_train_avg_90_red_w_015 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_90_red_w_015:.3f}, sum={y_test_sum_90_red_w_015}\")\n",
    "print(f\"Train steps: avg={y_train_avg_90_red_w_015:.3f}, sum={y_train_sum_90_red_w_015}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight BEST F1\n",
    " sample_weight = (abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps) + mu) + mu), where mu = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:58:05.475212Z",
     "start_time": "2023-11-30T13:57:23.836337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 50ms/step\n",
      "664/664 [==============================] - 34s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:59:41.929888Z",
     "start_time": "2023-11-30T13:59:41.623699Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted, 0.5th\n",
      "Test steps: avg=21.877, sum=92322\n",
      "Train steps: avg=24.029, sum=1020475\n",
      "\n",
      "Models results 90ep, red weighted, 0.35th\n",
      "Test steps: avg=21.779, sum=91906\n",
      "Train steps: avg=24.116, sum=1024169\n",
      "\n",
      "Models results 90ep, red weighted, 0.15th\n",
      "Test steps: avg=21.551, sum=90945\n",
      "Train steps: avg=24.085, sum=1022882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight\n",
    " if ri_steps < lo_steps:\n",
    "    sample_weight = abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps),\n",
    " else:\n",
    "    sample_weight = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:22.986259Z",
     "start_time": "2023-11-30T17:18:18.968833900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 10s 70ms/step\n",
      "664/664 [==============================] - 47s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted_v2.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:23.251496900Z",
     "start_time": "2023-11-30T17:19:22.990872100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.5th\n",
      "Test steps: avg=16.755, sum=70704\n",
      "Train steps: avg=15.591, sum=662125\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.35th\n",
      "Test steps: avg=16.754, sum=70702\n",
      "Train steps: avg=15.590, sum=662108\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.15th\n",
      "Test steps: avg=16.754, sum=70700\n",
      "Train steps: avg=15.590, sum=662094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight BEST F1\n",
    " if ri_steps < lo_steps:\n",
    "    sample_weight = abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps),\n",
    " else:\n",
    "    sample_weight = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:23:26.351620800Z",
     "start_time": "2023-11-30T17:22:32.343011400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 71ms/step\n",
      "664/664 [==============================] - 47s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted_v2.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:23:26.648939900Z",
     "start_time": "2023-11-30T17:23:26.356561900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.5th\n",
      "Test steps: avg=16.791, sum=70859\n",
      "Train steps: avg=15.968, sum=678127\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.35th\n",
      "Test steps: avg=16.783, sum=70825\n",
      "Train steps: avg=15.960, sum=677819\n",
      "\n",
      "Models results 90ep, red weighted v2, 0.15th\n",
      "Test steps: avg=16.774, sum=70785\n",
      "Train steps: avg=15.910, sum=675684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v2, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight\n",
    " if ri_steps > lo_steps:\n",
    "    sample_weight = abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps),\n",
    " else:\n",
    "    sample_weight = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T23:06:52.850519Z",
     "start_time": "2023-11-30T23:05:51.923081Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 7s 72ms/step\n",
      "664/664 [==============================] - 47s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted_v3.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T23:07:07.699460500Z",
     "start_time": "2023-11-30T23:07:07.430858500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.175, sum=941755\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.305, sum=947291\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.313, sum=947627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test 90 epoch with sample_weight BEST F1\n",
    " if ri_steps > lo_steps:\n",
    "    sample_weight = abs(ri_steps - lo_steps) / (max(ri_steps, lo_steps),\n",
    " else:\n",
    "    sample_weight = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T23:08:59.311902400Z",
     "start_time": "2023-11-30T23:07:49.229429200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 7s 70ms/step\n",
      "664/664 [==============================] - 62s 93ms/step\n"
     ]
    }
   ],
   "source": [
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted_v3.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T23:08:59.622875400Z",
     "start_time": "2023-11-30T23:08:59.315923800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.175, sum=941755\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.175, sum=941755\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=22.375, sum=94422\n",
      "Train steps: avg=22.175, sum=941755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 90 epoch with sample_weight\n",
    "\n",
    "* abs_diff = np.abs(ri_steps - li_steps)\n",
    "* abs_diff += 2\n",
    "* return np.log(abs_diff) - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 48ms/step\n",
      "664/664 [==============================] - 32s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted_v4.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.524, sum=90831\n",
      "Train steps: avg=23.906, sum=1015266\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.317, sum=89958\n",
      "Train steps: avg=23.957, sum=1017420\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=21.037, sum=88778\n",
      "Train steps: avg=23.733, sum=1007918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 90 epoch with sample_weight BEST F1\n",
    "\n",
    "* abs_diff = np.abs(ri_steps - li_steps)\n",
    "* abs_diff += 2\n",
    "* return np.log(abs_diff) - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 4s 48ms/step\n",
      "664/664 [==============================] - 35s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted_v4.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.858, sum=92240\n",
      "Train steps: avg=23.882, sum=1014260\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.586, sum=91095\n",
      "Train steps: avg=23.923, sum=1015972\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=21.006, sum=88647\n",
      "Train steps: avg=23.695, sum=1006318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 180 epoch with sample_weight\n",
    "sample_weight = np.abs(ri_steps - li_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 68ms/step\n",
      "664/664 [==============================] - 44s 66ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted_v6.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.293, sum=89858\n",
      "Train steps: avg=23.953, sum=1017259\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.021, sum=88710\n",
      "Train steps: avg=23.916, sum=1015672\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=20.630, sum=87060\n",
      "Train steps: avg=23.667, sum=1005133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 180 epoch with sample_weight, BEST F1\n",
    "sample_weight = np.abs(ri_steps - li_steps)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 5s 67ms/step\n",
      "664/664 [==============================] - 44s 66ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted_v6.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.445, sum=90498\n",
      "Train steps: avg=23.759, sum=1009008\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.139, sum=89205\n",
      "Train steps: avg=23.719, sum=1007338\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=20.624, sum=87034\n",
      "Train steps: avg=23.388, sum=993258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 90 epoch with sample_weight\n",
    "sample_weight = np.abs(ri_steps - li_steps) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 6s 50ms/step\n",
      "664/664 [==============================] - 33s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_red_weighted_v7.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.394, sum=90284\n",
      "Train steps: avg=23.629, sum=1003486\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.035, sum=88766\n",
      "Train steps: avg=23.613, sum=1002818\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=20.492, sum=86478\n",
      "Train steps: avg=23.098, sum=980931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 90 epoch with sample_weight, BEST F1\n",
    "sample_weight = np.abs(ri_steps - li_steps) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 4s 49ms/step\n",
      "664/664 [==============================] - 32s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights('./fine_models/model_ri_best_f1_red_weighted_v7.h5')\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BEST steps: avg=15.250, sum=64356\n",
      "Train BEST steps: avg=13.310, sum=565265\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.5th\n",
      "Test steps: avg=21.789, sum=91951\n",
      "Train steps: avg=23.463, sum=996460\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.35th\n",
      "Test steps: avg=21.509, sum=90767\n",
      "Train steps: avg=23.394, sum=993502\n",
      "\n",
      "Models results 90ep, red weighted v3, 0.15th\n",
      "Test steps: avg=20.743, sum=87535\n",
      "Train steps: avg=22.814, sum=968902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test BEST steps: avg={y_test_best_avg:.3f}, sum={y_test_best_sum}\")\n",
    "print(f\"Train BEST steps: avg={y_train_best_avg:.3f}, sum={y_train_best_sum}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.5th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.5)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.5)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.35th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.35)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.35)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")\n",
    "\n",
    "print(f\"Models results 90ep, red weighted v3, 0.15th\")\n",
    "y_test_sum_05, y_test_avg_05 = calc_steps_accuracy(y_test_pred, y_lo_test, y_ri_test, threshold=0.15)\n",
    "y_train_sum_05, y_train_avg_05 = calc_steps_accuracy(y_train_pred, y_lo_train, y_ri_train, threshold=0.15)\n",
    "print(f\"Test steps: avg={y_test_avg_05:.3f}, sum={y_test_sum_05}\")\n",
    "print(f\"Train steps: avg={y_train_avg_05:.3f}, sum={y_train_sum_05}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
