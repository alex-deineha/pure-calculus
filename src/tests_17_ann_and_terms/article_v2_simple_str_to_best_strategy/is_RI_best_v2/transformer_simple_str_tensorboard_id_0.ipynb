{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:49.412874Z",
     "start_time": "2023-11-23T14:25:38.293891Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Conv1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertConfig\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from calculus_path_mod.terms.pseudonym import *\n",
    "from calculus_path_mod.reduction_strategy import *\n",
    "from calculus_path_mod.terms.arithm_complex_ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:49.612043Z",
     "start_time": "2023-11-23T14:25:49.414892Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:49.685954Z",
     "start_time": "2023-11-23T14:25:49.620260Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sequence_len = 512\n",
    "batch_size = 64\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=9,\n",
    "    hidden_size=84,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=6,\n",
    "    intermediate_size=64,\n",
    "    max_position_embeddings=sequence_len,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load & Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:49.701961Z",
     "start_time": "2023-11-23T14:25:49.632980Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all terms: 4251\n",
      "\n",
      "Count original terms: 4251\n",
      "\n",
      "max RI steps count: 1000\n",
      "max LO steps count: 219\n",
      "Count TESTING samples: 4251\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../article_models_reduct_steps_by_simple_str/data_steps/steps_simple_term_str.csv\", delimiter=',')\n",
    "\n",
    "# leave only unique terms\n",
    "print(f\"Count all terms: {len(all_data)}\\n\")\n",
    "all_data = all_data.drop_duplicates(subset=\"simple_terms\").reset_index(drop=True)\n",
    "print(f\"Count original terms: {len(all_data)}\\n\")\n",
    "\n",
    "# shuffle the dataset\n",
    "all_data = shuffle(all_data, random_state=33).reset_index(drop=True)\n",
    "all_data = all_data.drop_duplicates([\"simple_terms\"])\n",
    "\n",
    "print(f\"max RI steps count: {max(all_data['RI_steps_num'])}\")\n",
    "print(f\"max LO steps count: {max(all_data['LO_steps_num'])}\")\n",
    "\n",
    "x_test = all_data[\"simple_terms\"].tolist()\n",
    "# RI has fewer steps -> 1\n",
    "# Otherwise 0\n",
    "y_test = [1 if los > ris else 0 for los, ris in zip(all_data[\"LO_steps_num\"].tolist(), all_data[\"RI_steps_num\"].tolist())]\n",
    "\n",
    "print(f\"Count TESTING samples: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:50.100337Z",
     "start_time": "2023-11-23T14:25:49.696069Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all terms: 44568\n",
      "\n",
      "Count original terms: 44568\n",
      "\n",
      "max RI steps count: 1000\n",
      "max LO steps count: 1000\n",
      "Count TRAINING samples: 44568\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../article_models_reduct_steps_by_simple_str/data_steps/steps_simple_term_str_extended.csv\", delimiter=',')\n",
    "\n",
    "# leave only unique terms\n",
    "print(f\"Count all terms: {len(all_data)}\\n\")\n",
    "all_data = all_data.drop_duplicates(subset=\"simple_terms\").reset_index(drop=True)\n",
    "print(f\"Count original terms: {len(all_data)}\\n\")\n",
    "\n",
    "# shuffle the dataset\n",
    "all_data = shuffle(all_data, random_state=33).reset_index(drop=True)\n",
    "all_data = all_data.drop_duplicates([\"simple_terms\"])\n",
    "\n",
    "print(f\"max RI steps count: {max(all_data['RI_steps_num'])}\")\n",
    "print(f\"max LO steps count: {max(all_data['LO_steps_num'])}\")\n",
    "\n",
    "x_train = all_data[\"simple_terms\"].tolist()\n",
    "# RI has fewer steps -> 1\n",
    "# Otherwise 0\n",
    "y_train = [1 if los > ris else 0 for los, ris in zip(all_data[\"LO_steps_num\"].tolist(), all_data[\"RI_steps_num\"].tolist())]\n",
    "\n",
    "print(f\"Count TRAINING samples: {len(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:25:50.174091Z",
     "start_time": "2023-11-23T14:25:50.045337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"../../transformers_to_lo_steps_prediciton/fine_models\", max_len=sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:01.292163Z",
     "start_time": "2023-11-23T14:25:50.078975Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = [x_.replace(\"@x.\", \"y\").replace(\" \", \"\") for x_ in x_train]\n",
    "x_test = [x_.replace(\"@x.\", \"y\").replace(\" \", \"\") for x_ in x_test]\n",
    "\n",
    "train_df = pd.DataFrame({\"term_str\": x_train, \"is_ri_best\": y_train})\n",
    "test_df = pd.DataFrame({\"term_str\": x_test, \"is_ri_best\": y_test})\n",
    "\n",
    "def preprocess(example):\n",
    "    # Tokenize the prompt\n",
    "    tokenized_texts = tokenizer(example['term_str'].to_list(), truncation=True, padding='max_length', max_length=sequence_len, return_tensors=\"tf\")\n",
    "    labels = tf.convert_to_tensor(example[\"is_ri_best\"])\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "\n",
    "tokenized_train_data = preprocess(train_df)\n",
    "tokenized_test_data = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:01.342221Z",
     "start_time": "2023-11-23T14:26:01.295575Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(tokenized_train_data[0]), tokenized_train_data[1])).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(tokenized_test_data[0]), tokenized_test_data[1])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:11.138719Z",
     "start_time": "2023-11-23T14:26:01.326402Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "from keras.layers import Dense, Input, Flatten, AveragePooling1D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "bert = TFBertModel(config=config)\n",
    "bert.build()\n",
    "\n",
    "input_ids_in = Input(shape=(sequence_len,), name='input_ids', dtype='int32')\n",
    "input_masks_in = Input(shape=(sequence_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embedding_layer = bert(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "outputs = AveragePooling1D(pool_size=50)(embedding_layer)\n",
    "outputs = Flatten()(outputs)\n",
    "outputs = Dropout(rate=0.1)(outputs)\n",
    "outputs = Dense(units=1, activation=\"sigmoid\")(outputs)\n",
    "model = Model(inputs=[input_ids_in, input_masks_in], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:11.217727Z",
     "start_time": "2023-11-23T14:26:11.142507Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  130832      ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 84),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 84),                                                           \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 10, 84)      0           ['tf_bert_model[0][0]']          \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 840)          0           ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 840)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            841         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131,673\n",
      "Trainable params: 131,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',\n",
    "                       tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall(),\n",
    "                       tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:11.290131Z",
     "start_time": "2023-11-23T14:26:11.218732Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model_structure = model.to_json()\n",
    "# with open(\"./fine_models/model_ri.json\", 'w') as json_file:\n",
    "#     json_file.write(model_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:26:11.295062Z",
     "start_time": "2023-11-23T14:26:11.234932Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the ModelCheckpoint callback\n",
    "f1_callback = ModelCheckpoint(\n",
    "    filepath='./fine_models/model_ri_best_f1_e10.h5',  # Specify the path to save the best model\n",
    "    monitor='val_f1_score',  # Metric to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='max',  # 'min' or 'max' depending on the monitored metric\n",
    "    verbose=0  # Print a message when saving the model\n",
    ")\n",
    "\n",
    "step_callback = ModelCheckpoint('./fine_models/model_ri_e10.h5', save_weights_only=True, save_freq=1)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"ri_best_logs/id_0\", histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:25.370796Z",
     "start_time": "2023-11-23T14:26:11.249697Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "697/697 [==============================] - 166s 231ms/step - loss: 0.3483 - accuracy: 0.8813 - precision: 0.2385 - recall: 0.0050 - f1_score: 0.0097 - val_loss: 0.2842 - val_accuracy: 0.9108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/10\n",
      "697/697 [==============================] - 161s 232ms/step - loss: 0.3297 - accuracy: 0.8832 - precision: 0.5972 - recall: 0.0164 - f1_score: 0.0320 - val_loss: 0.2737 - val_accuracy: 0.9108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/10\n",
      "697/697 [==============================] - 162s 232ms/step - loss: 0.3238 - accuracy: 0.8853 - precision: 0.7210 - recall: 0.0380 - f1_score: 0.0723 - val_loss: 0.2727 - val_accuracy: 0.9108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/10\n",
      "697/697 [==============================] - 162s 232ms/step - loss: 0.3207 - accuracy: 0.8866 - precision: 0.7374 - recall: 0.0531 - f1_score: 0.0991 - val_loss: 0.2738 - val_accuracy: 0.9108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/10\n",
      "697/697 [==============================] - 166s 238ms/step - loss: 0.3173 - accuracy: 0.8876 - precision: 0.7563 - recall: 0.0629 - f1_score: 0.1161 - val_loss: 0.2781 - val_accuracy: 0.9083 - val_precision: 0.2381 - val_recall: 0.0132 - val_f1_score: 0.0250\n",
      "Epoch 6/10\n",
      "697/697 [==============================] - 168s 241ms/step - loss: 0.3134 - accuracy: 0.8884 - precision: 0.7555 - recall: 0.0726 - f1_score: 0.1325 - val_loss: 0.2744 - val_accuracy: 0.9085 - val_precision: 0.2222 - val_recall: 0.0106 - val_f1_score: 0.0202\n",
      "Epoch 7/10\n",
      "697/697 [==============================] - 178s 256ms/step - loss: 0.3106 - accuracy: 0.8883 - precision: 0.7175 - recall: 0.0801 - f1_score: 0.1441 - val_loss: 0.2725 - val_accuracy: 0.9092 - val_precision: 0.2667 - val_recall: 0.0106 - val_f1_score: 0.0203\n",
      "Epoch 8/10\n",
      "697/697 [==============================] - 172s 247ms/step - loss: 0.3068 - accuracy: 0.8890 - precision: 0.7211 - recall: 0.0894 - f1_score: 0.1592 - val_loss: 0.2740 - val_accuracy: 0.9068 - val_precision: 0.1852 - val_recall: 0.0132 - val_f1_score: 0.0246\n",
      "Epoch 9/10\n",
      "697/697 [==============================] - 173s 248ms/step - loss: 0.3053 - accuracy: 0.8894 - precision: 0.7121 - recall: 0.0979 - f1_score: 0.1721 - val_loss: 0.2714 - val_accuracy: 0.9092 - val_precision: 0.2941 - val_recall: 0.0132 - val_f1_score: 0.0253\n",
      "Epoch 10/10\n",
      "697/697 [==============================] - 175s 250ms/step - loss: 0.3022 - accuracy: 0.8903 - precision: 0.7236 - recall: 0.1061 - f1_score: 0.1850 - val_loss: 0.2714 - val_accuracy: 0.9078 - val_precision: 0.2903 - val_recall: 0.0237 - val_f1_score: 0.0439\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, verbose=1, callbacks=[f1_callback, step_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:25.740059Z",
     "start_time": "2023-11-23T20:57:25.387796Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), history.history['loss'], label=\"loss\")\n",
    "plt.plot(range(1, epochs + 1), history.history['val_loss'], label=\"val_loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"total loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:25.945450Z",
     "start_time": "2023-11-23T20:57:25.739061Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), history.history['accuracy'], label=\"accuracy\")\n",
    "plt.plot(range(1, epochs + 1), history.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"total accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:26.094630Z",
     "start_time": "2023-11-23T20:57:25.940442Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), history.history['precision'], label=\"precision\")\n",
    "plt.plot(range(1, epochs + 1), history.history['val_precision'], label=\"val_precision\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"total precision\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:26.263502Z",
     "start_time": "2023-11-23T20:57:26.094630Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), history.history['recall'], label=\"recall\")\n",
    "plt.plot(range(1, epochs + 1), history.history['val_recall'], label=\"val_recall\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"total recall\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:26.434559Z",
     "start_time": "2023-11-23T20:57:26.265525Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), history.history['f1_score'], label=\"F1-score\")\n",
    "plt.plot(range(1, epochs + 1), history.history['val_f1_score'], label=\"val F1-score\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"total F1-score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:57:26.450027Z",
     "start_time": "2023-11-23T20:57:26.435570Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:20:53.542869Z",
     "start_time": "2023-11-23T21:20:53.519156Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual_labels, predicted_labels):\n",
    "    correct_predictions = sum(1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == predicted)\n",
    "    total_predictions = len(actual_labels)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, class_labels, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix of a classification model.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): The ground truth labels.\n",
    "        y_pred (numpy.ndarray): The predicted labels.\n",
    "        classes (list): The list of class labels.\n",
    "        class_labels: The list of class names.\n",
    "        normalize (bool, optional): Whether to normalize the confusion matrix. Defaults to False.\n",
    "        title (str, optional): The title of the plot. Defaults to None.\n",
    "        cmap (matplotlib.colors.Colormap, optional): The colormap to use for the plot. Defaults to plt.cm.Blues.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=classes).astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(class_labels)\n",
    "    ax.set_yticklabels(class_labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            ij = float(cm[i, j])\n",
    "            ax.text(j, i, f\"{ij:.2f}\", ha='center', va='center', color='white' if ij > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TRAINED MODEL (after 160 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:20.964724Z",
     "start_time": "2023-11-23T21:21:26.963348Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)\n",
    "\n",
    "y_test_nums = y_test\n",
    "y_train_nums = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:21.452986Z",
     "start_time": "2023-11-23T21:22:20.968875Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.15\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:21.916563Z",
     "start_time": "2023-11-23T21:22:21.449986Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.25\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:22.369386Z",
     "start_time": "2023-11-23T21:22:21.912538Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.35\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:22.814370Z",
     "start_time": "2023-11-23T21:22:22.361305Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True, title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T20:58:27.078182Z",
     "start_time": "2023-11-23T20:58:27.040200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Best validation F1-score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:22:43.422742Z",
     "start_time": "2023-11-23T21:22:42.921685Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "with open(\"./fine_models/model_ri.json\", \"r\") as file:\n",
    "    loaded_model_json = file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={\"TFBertModel\": TFBertModel})\n",
    "model.load_weights(\"./fine_models/model_ri_best_f1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:23:40.030521Z",
     "start_time": "2023-11-23T21:22:45.392962Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_dataset)\n",
    "y_train_pred = model.predict(train_dataset)\n",
    "\n",
    "y_test_nums = y_test\n",
    "y_train_nums = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:23:40.463905Z",
     "start_time": "2023-11-23T21:23:40.034338Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.15\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:23:40.946945Z",
     "start_time": "2023-11-23T21:23:40.464914Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.25\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:23:41.380943Z",
     "start_time": "2023-11-23T21:23:40.951784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.35\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T21:23:41.815259Z",
     "start_time": "2023-11-23T21:23:41.384053Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "y_test_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_test_pred]\n",
    "y_train_pred_nums = [0 if x_ < THRESHOLD else 1 for x_ in y_train_pred]\n",
    "\n",
    "print(\"Test accuracy:\", calculate_accuracy(y_test_nums, y_test_pred_nums))\n",
    "plot_confusion_matrix(y_test_nums, y_test_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")\n",
    "\n",
    "print(\"Train accuracy:\", calculate_accuracy(y_train_nums, y_train_pred_nums))\n",
    "plot_confusion_matrix(y_train_nums, y_train_pred_nums, classes=[0, 1], class_labels=[\"LO\", \"RI\"], normalize=True,\n",
    "                      title=f\"Test set, threshold={THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
