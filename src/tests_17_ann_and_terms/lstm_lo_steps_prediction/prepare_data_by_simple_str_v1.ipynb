{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:12:01.807894056Z",
     "start_time": "2023-10-16T15:12:01.512284654Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from joypy import joyplot\n",
    "\n",
    "sys.path.append(\"../../.\")\n",
    "from calculus_path_mod.term_engine import *\n",
    "from calculus_path_mod.reduction_strategy import *\n",
    "from calculus_path_mod.terms import num_comparison, nat_numbers, arithm_ops, combinators, pairs, logic\n",
    "from calculus_path_mod.terms.pseudonym import *\n",
    "\n",
    "from calculus_path_mod.json_serialization import load_terms\n",
    "from fitter import Fitter, get_common_distributions\n",
    "from calculus_utils.drawing import draw_steps_displot"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Terms filtered by LO & RI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "lists_terms_LO = [load_terms(f\"../../tests_11_retests/collected_terms/terms_210_filtered_LO_{inx_}.dat\") for inx_ in range(20)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:12:13.157534975Z",
     "start_time": "2023-10-16T15:12:12.286321664Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Collect more terms with normalization process data for LO & LI strategies with terms_LO & terms_RI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gen_norm_data(terms_list, strategy):\n",
    "    normalized_terms_dict = dict()\n",
    "    for term in tqdm(terms_list):\n",
    "        term_name = term.simple_str()\n",
    "        normalized_terms_dict[term_name] = []\n",
    "        term_red_steps = 0\n",
    "        (step_term, _, _), norm_term = term.one_step_normalize_visual(strategy)\n",
    "        normalized_terms_dict[term_name].append(step_term.simple_str())\n",
    "\n",
    "        while norm_term:\n",
    "            normalized_terms_dict[term_name].append(norm_term.simple_str())\n",
    "            (step_term, _, _), norm_term = norm_term.one_step_normalize_visual(strategy)\n",
    "\n",
    "            # computation limitation\n",
    "            if (step_term.vertices_number > 3_000) or (term_red_steps > 400):\n",
    "                norm_term = None\n",
    "    return normalized_terms_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:13:10.158780570Z",
     "start_time": "2023-10-16T15:13:10.108099306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [00:06<00:00, 33.91it/s]\n",
      "100%|██████████| 228/228 [00:02<00:00, 86.67it/s] \n",
      "100%|██████████| 222/222 [00:02<00:00, 109.40it/s]\n",
      "100%|██████████| 230/230 [00:04<00:00, 47.42it/s]\n",
      "100%|██████████| 231/231 [00:03<00:00, 64.64it/s] \n",
      "100%|██████████| 228/228 [00:01<00:00, 134.73it/s]\n",
      "100%|██████████| 233/233 [00:05<00:00, 44.18it/s]\n",
      "100%|██████████| 229/229 [00:04<00:00, 47.71it/s]\n",
      "100%|██████████| 227/227 [00:02<00:00, 112.02it/s]\n",
      "100%|██████████| 230/230 [00:05<00:00, 39.63it/s]\n",
      "100%|██████████| 220/220 [00:02<00:00, 74.35it/s] \n",
      "100%|██████████| 226/226 [00:05<00:00, 37.75it/s] \n",
      "100%|██████████| 224/224 [00:02<00:00, 75.41it/s]\n",
      "100%|██████████| 219/219 [00:02<00:00, 79.07it/s] \n",
      "100%|██████████| 219/219 [00:07<00:00, 28.03it/s] \n",
      "100%|██████████| 224/224 [00:03<00:00, 60.09it/s] \n",
      "100%|██████████| 222/222 [00:10<00:00, 20.77it/s] \n",
      "100%|██████████| 228/228 [00:02<00:00, 86.69it/s] \n",
      "100%|██████████| 223/223 [00:03<00:00, 57.37it/s] \n",
      "100%|██████████| 222/222 [00:01<00:00, 142.67it/s]\n"
     ]
    }
   ],
   "source": [
    "list_res_OO = [gen_norm_data(terms_LO, LOStrategy()) for terms_LO in lists_terms_LO]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:14:35.754140897Z",
     "start_time": "2023-10-16T15:13:11.170223013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "steps_lo = []\n",
    "simple_terms = []\n",
    "\n",
    "for res_ in list_res_OO:\n",
    "    for key_ in res_.keys():\n",
    "        list_red_steps = res_[key_]\n",
    "        total_steps = len(list_red_steps) - 1\n",
    "        for inx_ in range(total_steps + 1):\n",
    "            if list_red_steps[inx_] not in simple_terms:\n",
    "                simple_terms.append(list_red_steps[inx_])\n",
    "                steps_lo.append(total_steps - inx_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:15:24.140177302Z",
     "start_time": "2023-10-16T15:14:55.242175402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44568\n",
      "44568\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"steps_num_lo\": steps_lo, \"simple_terms\": simple_terms})\n",
    "print(len(df))\n",
    "df = df.drop_duplicates(subset=\"simple_terms\")\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:18:22.227123466Z",
     "start_time": "2023-10-16T15:18:22.134848614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "44568"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df[\"simple_terms\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:18:57.388095908Z",
     "start_time": "2023-10-16T15:18:57.344395419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/steps_simple_term_str_v1.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T15:19:07.364967778Z",
     "start_time": "2023-10-16T15:19:06.668109548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
