{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:51:29.844260Z",
     "start_time": "2024-03-19T15:51:28.994522Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key  = \"\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client = openai.AsyncOpenAI(\n",
    "  api_key=openai.api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "\n",
    "async def get_completion(prompt_, model_=\"gpt-3.5-turbo\"):\n",
    "    messages_ = [{\"role\": \"user\", \"content\": prompt_}]\n",
    "    response_ = await client.chat.completions.create(\n",
    "        model=model_, \n",
    "        messages=messages_,\n",
    "        temperature=0.00000001,\n",
    "    )\n",
    "    return response_.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:14.812722Z",
     "start_time": "2024-03-19T16:12:14.795214Z"
    }
   },
   "id": "fedf14af6c19d1fe",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4aac99258960f03"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected output: (λx.((λy.y) (λa.a)))\n",
      "model output: (λx.((λy.y) (λa.a)))\n"
     ]
    }
   ],
   "source": [
    "str_term = \"(λx.((λy.((λz.z) x)) (λa.a)))\"\n",
    "next_step_term = \"(λx.((λy.y) (λa.a)))\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please generate the next step of reduction a lambda term. Provide only term expression. Use the leftmost outermost strategy.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"expected output: {next_step_term}\")\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:02:38.002782Z",
     "start_time": "2024-03-19T16:02:36.539789Z"
    }
   },
   "id": "c07eb32bf14319bf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected output: (λx.((λy.y) x))\n",
      "model output: (λx.((λy.y) (λa.a)))\n"
     ]
    }
   ],
   "source": [
    "str_term = \"(λx.((λy.((λz.z) x)) (λa.a)))\"\n",
    "next_step_term = \"(λx.((λy.y) x))\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please generate the next step of reduction a lambda term. Provide only term expression. Use the rightmost innermost (RI) strategy.\n",
    "The RI strategy use the latest redex for reduction. Pay attention on this fact.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"expected output: {next_step_term}\")\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:05:17.647011Z",
     "start_time": "2024-03-19T16:05:16.636375Z"
    }
   },
   "id": "7430d85591f1fc94",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: (λx.((λy.x) (λa.a)))\n"
     ]
    }
   ],
   "source": [
    "str_term = \"(λx.((λy.[(λz.z) x]) (λa.a)))\"\n",
    "prompt = f\"\"\"\n",
    "Please generate the next step of reduction a lambda term.\n",
    "The reduction redex is selected with square brackets.\n",
    "\n",
    "Provide only term expression.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:07:28.978408Z",
     "start_time": "2024-03-19T16:07:27.897381Z"
    }
   },
   "id": "f52f04d7d3fa11d8",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: (λx.((λy.((λz.z) x)) (λa.a))) [x/(λa.a)]\n"
     ]
    }
   ],
   "source": [
    "str_term = \"[λx.((λy.((λz.z) x)) (λa.a))]\"\n",
    "prompt = f\"\"\"\n",
    "Please generate the next step of reduction a lambda term.\n",
    "The reduction redex is selected with square brackets.\n",
    "\n",
    "Provide only term expression.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:33.290627Z",
     "start_time": "2024-03-19T16:12:32.156632Z"
    }
   },
   "id": "151047c95104156f",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: (λx.((λy.((λz.z) x)) (λa.a))) \n",
      "→ (λx.((λz.z) x) (λa.a))\n"
     ]
    }
   ],
   "source": [
    "str_term = \"[λx.((λy.((λz.z) x)) (λa.a))]\"\n",
    "prompt = f\"\"\"\n",
    "Please execute a lambda term, do one step of execution using a selected redex.\n",
    "The redex is selected with square brackets.\n",
    "Provide only the next term expression.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:14:17.571214Z",
     "start_time": "2024-03-19T16:14:16.133158Z"
    }
   },
   "id": "5bd16512ba6d0779",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "str_term = \"(λx.((λy.((λz.z) x)) (λa.a)))\"\n",
    "enc_tiktoken = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "term_enc = enc_tiktoken.encode(str_term)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:20:37.488017Z",
     "start_time": "2024-03-19T16:20:37.066922Z"
    }
   },
   "id": "22a988fb4f97e1f",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: (\n",
      "34586: λ\n",
      "87: x\n",
      "13: .\n",
      "1209: ((\n",
      "34586: λ\n",
      "88: y\n",
      "13: .\n",
      "1209: ((\n",
      "34586: λ\n",
      "89: z\n",
      "4025: .z\n",
      "8: )\n",
      "865:  x\n",
      "595: ))\n",
      "320:  (\n",
      "34586: λ\n",
      "64: a\n",
      "5973: .a\n",
      "7861: )))\n"
     ]
    }
   ],
   "source": [
    "for enc_token in term_enc:\n",
    "    print(f\"{enc_token}: {enc_tiktoken.decode([enc_token,])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:21:54.915495Z",
     "start_time": "2024-03-19T16:21:54.908602Z"
    }
   },
   "id": "900fca3b864fcc24",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: (\n",
      "49438:  λ\n",
      "865:  x\n",
      "662:  .\n",
      "320:  (\n",
      "320:  (\n",
      "49438:  λ\n",
      "379:  y\n",
      "662:  .\n",
      "320:  (\n",
      "320:  (\n",
      "49438:  λ\n",
      "1167:  z\n",
      "662:  .\n",
      "1167:  z\n",
      "883:  )\n",
      "865:  x\n",
      "883:  )\n",
      "883:  )\n",
      "320:  (\n",
      "49438:  λ\n",
      "264:  a\n",
      "662:  .\n",
      "264:  a\n",
      "883:  )\n",
      "883:  )\n",
      "883:  )\n"
     ]
    }
   ],
   "source": [
    "str_term = \"( λ x . ( ( λ y . ( ( λ z . z ) x ) ) ( λ a . a ) ) )\"\n",
    "enc_tiktoken = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "term_enc = enc_tiktoken.encode(str_term)\n",
    "for enc_token in term_enc:\n",
    "    print(f\"{enc_token}: {enc_tiktoken.decode([enc_token, ])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:23:23.004958Z",
     "start_time": "2024-03-19T16:23:22.997797Z"
    }
   },
   "id": "e1e1c9f6222a0531",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: ( λ y . ( ( λ z . z ) ( λ a . a ) ) )\n"
     ]
    }
   ],
   "source": [
    "str_term = \"[ λ x . ( ( λ y . ( ( λ z . z ) x) ) ( λ a . a ) ) ]\"\n",
    "prompt = f\"\"\"\n",
    "Please execute a lambda term, do one step of execution using a selected redex.\n",
    "The redex is selected with square brackets.\n",
    "Provide only the next term expression.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:25:41.645276Z",
     "start_time": "2024-03-19T16:25:40.567524Z"
    }
   },
   "id": "2aead70fb0532f43",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: ( ( λ y . ( ( λ z . z ) x) ) ( λ a . a ) )\n"
     ]
    }
   ],
   "source": [
    "str_term = \"( λ x . ( ( λ y . ( ( λ z . z ) x) ) ( λ a . a ) ) )\"\n",
    "prompt = f\"\"\"\n",
    "Please execute a lambda term, do one step of execution using a selected redex.\n",
    "Provide only the next term expression.\n",
    "\n",
    "Lambda term: '''{str_term}'''\n",
    "\"\"\"\n",
    "response = await get_completion(prompt)\n",
    "print(f\"model output: {response}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:26:56.071277Z",
     "start_time": "2024-03-19T16:26:55.087191Z"
    }
   },
   "id": "d45892c0ba949bfa",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1542dffa7f8c1c2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3be223925b4ff498"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92e4eff926826fb2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b890652a54817005"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
