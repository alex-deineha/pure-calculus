{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:42:55.004541Z",
     "end_time": "2023-06-08T17:42:55.117552Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from calculus_path_mod.term_engine import *\n",
    "from calculus_path_mod.reduction_strategy import *\n",
    "from calculus_path_mod.terms import num_comparison, nat_numbers, arithm_ops, combinators, pairs, logic\n",
    "\n",
    "from calculus_path_mod.terms.pseudonym import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "FIB = \"\"\"\n",
    "(Y (@f. (@pp. (\n",
    "    IF (ISZERO (FIRST pp))\n",
    "        (FIRST (SECOND pp))\n",
    "        (f (PAIR\n",
    "            (PRED (FIRST pp))\n",
    "            (PAIR\n",
    "                (SECOND (SECOND pp))\n",
    "                (PLUS (FIRST (SECOND pp)) (SECOND (SECOND pp)))\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "))\n",
    ")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:01.892110Z",
     "end_time": "2023-06-08T17:44:01.896628Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "LAMBDA_COMMANDS_DICT = {\n",
    "    # logic\n",
    "    \"TRUE\": \"logic.true_term()\",\n",
    "    \"FALSE\": \"logic.false_term()\",\n",
    "    \"IF\": \"logic.ite_term()\",\n",
    "    \"ITE\": \"logic.ite_term()\",\n",
    "    \"NOT\": \"logic.not_term()\",\n",
    "    \"AND\": \"logic.and_term()\",\n",
    "    \"OR\": \"logic.or_term()\",\n",
    "\n",
    "    # combinators\n",
    "    \"K\": \"combinators.k_term()\",\n",
    "    \"K_STAR\": \"combinators.k_star_term()\",\n",
    "    \"S\": \"combinators.s_term()\",\n",
    "    \"I\": \"combinators.i_term()\",\n",
    "    \"Y\": \"combinators.y_term()\",\n",
    "    \"Z\": \"combinators.z_term()\",\n",
    "    \"ETTA_V\": \"combinators.etta_v_term()\",\n",
    "\n",
    "    # nat numbers\n",
    "    \"NUM\": \"nat_numbers.num_term(\",\n",
    "\n",
    "    # num comparison\n",
    "    \"ISZERO\": \"num_comparison.iszero_term()\",\n",
    "    \"LEQ\": \"num_comparison.leq_term()\",\n",
    "    \"EQ\": \"num_comparison.eq_term()\",\n",
    "    \"LT\": \"num_comparison.lt_term()\",\n",
    "    \"NEQ\": \"num_comparison.neq_term()\",\n",
    "    \"GEQ\": \"num_comparison.geq_term()\",\n",
    "    \"GT\": \"num_comparison.gt_term()\",\n",
    "\n",
    "    # pairs\n",
    "    \"PAIR\": \"pairs.pair_term()\",\n",
    "    \"FIRST\": \"pairs.first_term()\",\n",
    "    \"SECOND\": \"pairs.second_term()\",\n",
    "\n",
    "    # arithm ops\n",
    "    \"SUCC\": \"arithm_ops.succ_term()\",\n",
    "    \"SINC\": \"arithm_ops.sinc_term()\",\n",
    "    \"PRED\": \"arithm_ops.pred_term()\",\n",
    "    \"SUBTRACT\": \"arithm_ops.subtract_term()\",\n",
    "    \"MINUS\": \"arithm_ops.subtract_term()\",\n",
    "    \"DIV\": \"arithm_ops.div_term()\",\n",
    "    \"MOD\": \"arithm_ops.mod_term()\",\n",
    "    \"IDIV\": \"arithm_ops.idiv_term()\",\n",
    "    \"PLUS\": \"arithm_ops.plus_term()\",\n",
    "    \"SUM\": \"arithm_ops.plus_term()\",\n",
    "    \"MULT\": \"arithm_ops.mult_term()\",\n",
    "}\n",
    "\n",
    "\n",
    "def tokenize_term(lambda_code) -> list:\n",
    "    brackets_counter = 0\n",
    "    is_not_tokenized = True\n",
    "\n",
    "    is_not_space_delimited = True\n",
    "\n",
    "    lambda_code_tokenized = \"\"\n",
    "    for symbol in lambda_code:\n",
    "        if symbol == \"(\":\n",
    "            brackets_counter += 1\n",
    "        if symbol == \")\":\n",
    "            brackets_counter -= 1\n",
    "        if brackets_counter == 0:\n",
    "            is_not_tokenized = True\n",
    "        if brackets_counter == 1:\n",
    "            if is_not_tokenized:\n",
    "                lambda_code_tokenized += \"><\"\n",
    "                is_not_tokenized = False\n",
    "        if brackets_counter == 0:\n",
    "            if is_not_space_delimited:\n",
    "                if symbol == \" \":\n",
    "                    lambda_code_tokenized += \"><\"\n",
    "                    is_not_space_delimited = False\n",
    "            else:\n",
    "                if symbol != \" \":\n",
    "                    is_not_space_delimited = True\n",
    "\n",
    "        lambda_code_tokenized += symbol\n",
    "\n",
    "    lambda_code_tokenized = [token.strip() for token in lambda_code_tokenized.split(\"><\")]\n",
    "    lambda_code_tokenized = [token for token in lambda_code_tokenized if token != \"\"]\n",
    "\n",
    "    return lambda_code_tokenized\n",
    "\n",
    "\n",
    "def process_tokens_to_pt(lambda_code: str, vars_list: list) -> str:\n",
    "    # is abstraction\n",
    "    if re.match(r\"\\s*\\(\\s*@\\s*[a-zA-Z0-9_-].\\s*\", lambda_code):\n",
    "        inx_open = 0\n",
    "        inx_close = -1\n",
    "\n",
    "        # remove outer brackets\n",
    "        while lambda_code[inx_open] != \"(\":\n",
    "            inx_open += 1\n",
    "        while lambda_code[inx_close] != \")\":\n",
    "            inx_close -= 1\n",
    "        lambda_code = lambda_code[inx_open + 1: inx_close]\n",
    "\n",
    "        inx_open = 0\n",
    "        while lambda_code[inx_open] != \".\":\n",
    "            inx_open += 1\n",
    "\n",
    "        var_name = lambda_code[:inx_open]\n",
    "        lambda_code = lambda_code[inx_open + 1:]\n",
    "\n",
    "        for var in vars_list:\n",
    "            if var in var_name:\n",
    "                var_name = var\n",
    "                break\n",
    "\n",
    "        return f\"Lambda({var_name}, {process_tokens_to_pt(lambda_code, vars_list)})\"\n",
    "    else:  # it is an app or a single term\n",
    "        if (\"(\" in lambda_code) and (\")\" in lambda_code):  # it is an app\n",
    "            inx_open = 0\n",
    "            inx_close = -1\n",
    "\n",
    "            # remove outer brackets\n",
    "            while lambda_code[inx_open] != \"(\":\n",
    "                inx_open += 1\n",
    "            while lambda_code[inx_close] != \")\":\n",
    "                inx_close -= 1\n",
    "            lambda_code = lambda_code[inx_open + 1: inx_close]\n",
    "\n",
    "            tokens = tokenize_term(lambda_code)\n",
    "            if len(tokens) == 0:\n",
    "                raise Exception(\"Something went wrong\")\n",
    "            elif len(tokens) == 1:\n",
    "                return process_tokens_to_pt(tokens[0], vars_list)\n",
    "            elif len(tokens) == 2:\n",
    "                return f\"App({process_tokens_to_pt(tokens[0], vars_list)}, {process_tokens_to_pt(tokens[1], vars_list)})\"\n",
    "            else:\n",
    "                result_line = \"multi_app_term(\"\n",
    "                for token in tokens:\n",
    "                    result_line += str(process_tokens_to_pt(token, vars_list)) + \", \"\n",
    "                result_line += \")\"\n",
    "                return result_line\n",
    "        else:  # it is a single term\n",
    "            lambda_code = lambda_code.strip()\n",
    "            if lambda_code in LAMBDA_COMMANDS_DICT.keys():\n",
    "                return LAMBDA_COMMANDS_DICT[lambda_code]\n",
    "            else:\n",
    "                if (\".\" in lambda_code) \\\n",
    "                        or (\"@\" in lambda_code):\n",
    "                    raise Exception(\"Not allowed symbol in Lambda term\")\n",
    "                if (\"NUM\" in lambda_code) and (\"[\" in lambda_code) and (\"]\" in lambda_code):\n",
    "                    try:\n",
    "                        num = int(lambda_code.strip().split(\"[\")[1][:-1])\n",
    "                        return LAMBDA_COMMANDS_DICT[\"NUM\"] + str(num) + \")\"\n",
    "                    except:\n",
    "                        raise Exception(\"Can't parse number\")\n",
    "                return lambda_code + \"_\"\n",
    "            pass\n",
    "\n",
    "\n",
    "def convert_to_python_code(lambda_code: str) -> str:\n",
    "    # remove \"\\n\", \"\\t\", and outer spaces symbol\n",
    "    lambda_code = lambda_code.replace(\"\\n\", \"\").replace(\"\\t\", \" \").strip()\n",
    "    if lambda_code == \"\":\n",
    "        raise Exception(\"Can't convert to lambda term an empty value\")\n",
    "\n",
    "    # check brackets\n",
    "    count_open_brackets = lambda_code.count(\"(\")\n",
    "    count_close_brackets = lambda_code.count(\")\")\n",
    "    if count_open_brackets != count_close_brackets:\n",
    "        raise Exception(\n",
    "            f\"Wrong count brackets, can't interpreter this cause '(' = {count_open_brackets}, ')' = {count_close_brackets}\")\n",
    "\n",
    "    # remove redundant spaces\n",
    "    lambda_code = re.sub(r\"\\s+\", \" \", lambda_code)\n",
    "\n",
    "    # find variables & atom terms\n",
    "    vars_atoms_list = lambda_code.replace(\"(\", \" \").replace(\")\", \" \").replace(\".\", \" \").replace(\"@\", \" \")\n",
    "    vars_atoms_list = re.sub(r\"\\s+\", \" \", vars_atoms_list)\n",
    "    vars_atoms_list = vars_atoms_list.split()\n",
    "    vars_atoms_list = [va_name for va_name in vars_atoms_list if va_name not in LAMBDA_COMMANDS_DICT.keys()]\n",
    "    vars_atoms_list = list(set(vars_atoms_list))\n",
    "\n",
    "    result_line = \"def gen_term():\\n\"\n",
    "    for var_name in vars_atoms_list:\n",
    "        result_line += \"\\t\" + var_name + \" = Var()\\n\"\n",
    "        result_line += \"\\t\" + var_name + f\"_ = Atom({var_name})\\n\"\n",
    "\n",
    "    result_line += \"\\n\\tresult_term = \" + process_tokens_to_pt(lambda_code, vars_atoms_list)\n",
    "    result_line += \"\\n\\treturn result_term\"\n",
    "    return result_line\n",
    "\n",
    "\n",
    "def conv_to_term(lambda_code: str) -> Term:\n",
    "    # define a function for generating a term\n",
    "    # using exec() and call this function to get result\n",
    "    exec(convert_to_python_code(lambda_code))\n",
    "    return eval(\"gen_term()\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:42:58.397514Z",
     "end_time": "2023-06-08T17:42:58.403476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "strategy_lo = LOStrategy()\n",
    "strategy_li = LIStrategy()\n",
    "strategy_ri = RIStrategy()\n",
    "\n",
    "\n",
    "def test_term(strategy_name, idx):\n",
    "    strategy = None\n",
    "    if strategy_name == \"LO\":\n",
    "        strategy = strategy_lo\n",
    "    elif strategy_name == \"LI\":\n",
    "        strategy = strategy_li\n",
    "    elif strategy_name == \"RI\":\n",
    "        strategy = strategy_ri\n",
    "    if not strategy:\n",
    "        return\n",
    "\n",
    "    fib_idx = App(conv_to_term(FIB), multi_app_term(pairs.pair_term(),\n",
    "                                              nat_numbers.num_term(idx),\n",
    "                                              multi_app_term(pairs.pair_term(), nat_numbers.num_term(0),\n",
    "                                                             nat_numbers.num_term(1))))\n",
    "    norm_term, steps = fib_idx.normalize(strategy, is_limited=False)\n",
    "    print(f\"{strategy_name}: {steps} {norm_term.funky_str()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:06.777915Z",
     "end_time": "2023-06-08T17:44:06.784475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO: 30 (λx.(λy.y))\n"
     ]
    }
   ],
   "source": [
    "test_term(\"LO\", 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:10.416516Z",
     "end_time": "2023-06-08T17:44:10.471524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO: 82 (λx.(λy.(x y)))\n"
     ]
    }
   ],
   "source": [
    "test_term(\"LO\", 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:13.255807Z",
     "end_time": "2023-06-08T17:44:13.732268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO: 187 (λx.(λy.(x y)))\n"
     ]
    }
   ],
   "source": [
    "test_term(\"LO\", 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:13.734717Z",
     "end_time": "2023-06-08T17:44:16.999221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO: 348 (λx.(λy.(x (x y))))\n"
     ]
    }
   ],
   "source": [
    "test_term(\"LO\", 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:17.001995Z",
     "end_time": "2023-06-08T17:44:37.986376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO: 597 (λx.(λy.(x (x (x y)))))\n"
     ]
    }
   ],
   "source": [
    "test_term(\"LO\", 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T17:44:37.985346Z",
     "end_time": "2023-06-08T17:47:20.566148Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
