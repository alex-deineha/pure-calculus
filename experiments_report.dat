dir "tests"
    * "e_greedy_determ_vs_non_determ_test.ipynb"
        Just simple run and comparison of average steps count generated by e-greedy and greedy approaches.
    * "e_greedy_policy_test.ipynb"
        Simple run and drawing steps graphics for e-greedy policy.
    * "greedy_policy_test.ipynb"
        Simple run and drawing steps graphics for greedy policy.

dir "tests_2"
    * "p_calc_egreedy_ndet_act_outliers.ipynb"
        Experiments with removing outlier steps in resulting steps. It was need for correct graphic drawing.
    * "p_calc_egreedy_ndet_action_based.ipynb"
        Modification of the e-greedy and greedy policy with using action based exploitation process.
    * "p_calc_vs_l_env.ipynb"
        Comparing correctness of my function for lambda reduction (used in own lambda env)
        and a function's created by Vlad.
    * "pure_calculus_clear.ipynb"
        The same "PureCalculus.ipynb" notebook but with code simplifying.
    * "pure_calculus_vs_e_greedy_non_determ.ipynb"
        Here we got simply draw graphics of steps comparison for e-Greedy-steps, LO-steps, RI-steps, and Rand-steps.
    * "pure_calculus_vs_greedy.ipynb"
        Here we got simply draw graphics of steps comparison for Greedy-steps, LO-steps, RI-steps, and Rand-steps.

dir "tests_3_reproducibility"
    * "p_calc_egreedy_act_clear_reprod_test.ipynb"
        Generated 100 terms 5 times (total 500 terms) and each of generation normalized via LO, RI and Rand strategy.
        After that, we did action based e-greedy normalization with deterministic and non-deterministic approach.
        For all 5 normalization steps build 5 avg-cum graphics (with and without cleaning outliers).
    * "p_calc_egreedy_act_clear_reprod_v2.ipynb"
        Generated 100 terms 10 times (total 1000 terms) and each of generation normalized via LO, RI and Rand strategy.
        After that, we did action based e-greedy normalization with deterministic and non-deterministic approach.
        For all 5 normalization steps build 10 avg-cum graphics (with and without cleaning outliers).
    * "p_calc_egreedy_act_clear_reprod_v3.ipynb"
        Generated 200 terms 5 times (total 1000 terms) and each of generation normalized via LO, RI and Rand strategy.
        After that, we did action based e-greedy normalization with deterministic and non-deterministic approach.
        For all 5 normalization steps build 5 avg-cum graphics (with and without cleaning outliers).
    * "p_calc_egrndet_act_run_1000.ipynb"
        Generated 1_000 terms, and normalized via LO, RI and Rand strategy.
        After that, we did action based e-greedy normalization with deterministic and non-deterministic approach.
        For all 5 normalization steps build 5 avg-cum graphics (with and without cleaning outliers).

dir "tests_4_probabilities"
    dir "test_4_1_reward_repro"
        * "env_reward_experiments.ipynb"
            Generate 200 terms and run it on LO, RI, Rand as starting point.
            Then run a new reward mod env with different configurations, look at results.
             > Reward distributions (test_1): 1:10, 1:11
             > Reward distributions (test_2): 1:1, 1:4, 1:16, 1:32, 1:64, 1:128
            For this built avg-cum and strategy-weights graphics for each experiment.
        * "env_reward_exps_2.ipynb"
            // the same
        * "env_reward_exps_3.ipynb"
            // the same
        * "env_reward_exps_4.ipynb"
            // the same
        * "env_reward_exps_5.ipynb"
            // the same
    * "draw_probabilities.ipynb"
        For e-greedy policy draw strategy-weights graphics (probability of choosing a strategy Vs step number)
        Compared graphics for 100 and 200 terms.
    * "p_calc_egrndet_act_run_1000_2_5.ipynb"
        Generated 1_000 terms and studied it on the env(LO, RI) and env(LO, LI, RI, RO, Rand), each env trained on
        the e-greedy action based non-deterministic.
        Results were shown on strategy-weights graphics (probability of choosing a strategy Vs step number) for
        the 2-strategies env and 5-strategies env.
    * "p_calc_find_optimal.ipynb"
        Generate 400 terms and find out optimal weights through Vladâ€™s evolving procedure.
        Also here tested MixedStrategy([LO, RI], (0.85, 0.15)), and got not the most optimal results.
    * "p_calc_prop_no_cleaning_t400.ipynb"
        Count generated terms 400
        Testing with different probabilities of strategies (total 21 trials) in the loop
        For this took 100 terms and run it via mixed strategy of LO & RI
    * "p_calc_probabilities_test.ipynb"
        Count generated terms 100, but with removing unnormalizable by RI or Rand strategy terms.
        Testing with different probabilities of strategies (total 21 trials) in the loop
        For this took 100 terms and run it via mixed strategy of LO & RI
    * "p_calc_probabilities_test_no_cleaning.ipynb"
        Count generated terms 100
        Testing with different probabilities of strategies (total 21 trials) in the loop
        For this took 100 terms and run it via mixed strategy of LO & RI

dir "test_5"
    * "bool_and_arithmetics_to_terms.ipynb"
        Realization boolean logic and arithmetic via lambda calculus and after it generation,
        and after realization program term (Euclidian algorithm) and data term (I suppose simply numbers)
        try it on our approach.
    * "c_calc_by_different_filters.ipynb"
        Generating terms with non-standard term filtering, testing it via LO, RI, LI, RO and drawing
        it's results (lice avg-cum graphics), and testing via MixedStrategy with different probabilities.
        As filtering used LI, RI, RO, and LO (default approach).
    * "c_calc_by_filter_max_avg_lo.ipynb"
        Generating terms with non-standard term filtering via LO & RI but with balancing by steps count,
        Rand and drawing it's results (lice avg-cum graphics), and testing via MixedStrategy with different
        probabilities.
    * "c_calc_by_mixed_strategy_filter.ipynb"
        Generating terms with non-standard term filtering, testing it via MixedStrategy(LO, RI) and
        MixedStrategy(LO, LI, RI, RO, Rand) and drawing it's results (lice avg-cum graphics),
        and testing via MixedStrategy with different probabilities.





