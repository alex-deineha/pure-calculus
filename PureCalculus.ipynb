{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "PureCalculus.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQIil37NA0Ji"
   },
   "source": [
    "# **Pure $\\lambda$-Calculus**\n",
    "\n",
    "[The deatailed script](https://www.mathcha.io/editor/Pvvz5UZ1t7ktL6sZJYp19sZnX9vVserJMEKhJvvMx7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt59KyGy-o-f"
   },
   "source": [
    "## **Variables**\n",
    "\n",
    "The code below models variables.\n",
    "\n",
    "Using the `natgen()` generator in this code ensures that a fresh variable is returned in response to each constructor call."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pj7-5rLvtVsV"
   },
   "source": [
    "def natgen():\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "\n",
    "class Var:\n",
    "    __nats = natgen()\n",
    "\n",
    "    def __init__(self):\n",
    "        self._idx = next(Var.__nats)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self._idx.__hash__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"v[\" + str(self._idx) + \"]\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._idx == other._idx"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljb-CYMMKFqw"
   },
   "source": [
    "## **Terms**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jgewYUUzt3nA"
   },
   "source": [
    "class Term:\n",
    "\n",
    "    @property\n",
    "    def isAtom(self):\n",
    "        \"\"\"checks whether the term is an atom\"\"\"\n",
    "        return isinstance(self, Atom)\n",
    "\n",
    "    @property\n",
    "    def isApplication(self):\n",
    "        \"\"\"checks whether the term is an application\"\"\"\n",
    "        return isinstance(self, Application)\n",
    "\n",
    "    @property\n",
    "    def isAbstraction(self):\n",
    "        \"\"\"checks whether the term is an abstraction\"\"\"\n",
    "        return isinstance(self, Abstraction)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.isAtom:\n",
    "            return str(self._var)\n",
    "        if self.isApplication:\n",
    "            return \"(\" + str(self._sub) + \" \" + str(self._obj) + \")\"\n",
    "        # self is Abbstraction\n",
    "        return \"(fun \" + str(self._head) + \" => \" + str(self._body) + \")\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if self.isAtom and other.isAtom:\n",
    "            return self._var == other._var\n",
    "        if isinstance(self, Application) and isinstance(other, Application):\n",
    "            return self._sub == other._sub and self._obj == other._obj\n",
    "        if isinstance(self, Abstraction) and isinstance(other, Abstraction):\n",
    "            return self._head == other._head and self._body == other._body\n",
    "\n",
    "    @property\n",
    "    def isBetaRedex(self):\n",
    "        \"\"\"checks whether the term is a beta-redex\"\"\"\n",
    "        return self.isApplication and self._sub.isAbstraction\n",
    "\n",
    "    @property\n",
    "    def redexes(self):\n",
    "        \"\"\"determiness all beta-redexes in the term\"\"\"\n",
    "        if self.isAtom:\n",
    "            return []\n",
    "        if self.isAbstraction:\n",
    "            return self._body.redexes\n",
    "        # self is Application\n",
    "        temp = [self ]if self.isBetaRedex else []\n",
    "        temp += (self._sub.redexes + self._obj.redexes)\n",
    "        return temp\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _vars(self):\n",
    "        \"\"\"\n",
    "        returns\n",
    "        -------\n",
    "            the dictionary stuctured as follows\n",
    "                dict[Var, dict[['free' | 'bound'], int]]\n",
    "            Here, keys of the external dictionary are the variables that\n",
    "            are occurred in 'self', and values of the internal dictionaries\n",
    "            relate respectively to the numbers of free and bound occurrences\n",
    "            of the variables.\n",
    "        \"\"\"\n",
    "        if self.isAtom:\n",
    "            return {self._var: {'free': 1, 'bound': 0}}\n",
    "        if self.isApplication:\n",
    "            vars, auxvars = dict(self._sub._vars), self._obj._vars\n",
    "            for var in auxvars:\n",
    "                try:\n",
    "                    for key in {'free', 'bound'}:\n",
    "                       vars[var][key] += self._obj._vars[var][key]\n",
    "                except KeyError:\n",
    "                    vars[var] = dict(self._obj._vars[var])\n",
    "            return vars\n",
    "        # self is Abstraction\n",
    "        vars = dict(self._body._vars)\n",
    "        try:\n",
    "            vars[self._head]['bound'] += vars[self._head]['free']\n",
    "            vars[self._head]['free'] = 0\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return vars\n",
    "\n",
    "    @property\n",
    "    def verticesNumber(self):\n",
    "      \"\"\"return the number of nodes in the tree representing the lambda term\"\"\"\n",
    "      if self.isAtom:\n",
    "        return 1\n",
    "      elif self.isApplication:\n",
    "        return 1 + self._sub.verticesNumber + self._obj.verticesNumber\n",
    "      else: # self is Abstraction\n",
    "        return 1 + self._body.verticesNumber \n",
    "\n",
    "    def hasNormalForm(self, strategy):\n",
    "      \"\"\"\n",
    "      :param strategy: OneStepStrategy\n",
    "      \"\"\"\n",
    "      term = self._updateBoundVariables()\n",
    "      count = 0\n",
    "      while term.redexes != []:\n",
    "        term = term._betaConversion(strategy)\n",
    "        count += 1\n",
    "        if term.verticesNumber > 100000 or count > 2000:\n",
    "          return False\n",
    "      return True    \n",
    "\n",
    "    def normalize(self, strategy):\n",
    "      \"\"\"\n",
    "      :param strategy: OneStepStrategy\n",
    "      :return tuple of the normal form of the term and number of steps of betta reduction\n",
    "      \"\"\"\n",
    "      term = self._updateBoundVariables()\n",
    "      count = 0\n",
    "      while term.redexes != []:\n",
    "        term = term._betaConversion(strategy)\n",
    "        count += 1\n",
    "      return (term, count)\n",
    "\n",
    "    def _betaConversion(self, strategy):\n",
    "      \"\"\"\n",
    "      :param strategy: OneStepStrategy\n",
    "      :return term with redex eliminated using the given strategy\n",
    "      \"\"\"\n",
    "      index = strategy.redexIndex(self)\n",
    "      subterm = self.subterm(index)\n",
    "      reducedTerm = subterm._removeOuterRedex()\n",
    "      return self.setSubterm(index, reducedTerm)\n",
    "\n",
    "    def subterm(self, index: int):\n",
    "      \"\"\"\n",
    "      By representing the term as a tree, a subtree is returned, which is also a lambda term.\n",
    "      The vertex of this subtree has a given index in the topological sorting of the vertices of the original term.\n",
    "      :param index - subterm index\n",
    "      :return: subterm: Term\n",
    "      \"\"\"\n",
    "      if index == 1:\n",
    "        return self\n",
    "\n",
    "      if self.isAtom:\n",
    "        ValueError('index value is incorrect')\n",
    "      elif self.isApplication:\n",
    "        if self._sub.verticesNumber + 1 >= index:\n",
    "          return self._sub.subterm(index - 1)\n",
    "        else:\n",
    "          return self._obj.subterm(index - self._sub.verticesNumber - 1)\n",
    "      else: # self is Abstraction\n",
    "        return self._body.subterm(index - 1)\n",
    "\n",
    "    def setSubterm(self, index: int, term):\n",
    "      \"\"\"\n",
    "      By representing the term as a tree, a subtree is set, which is also a lambda term.\n",
    "      The vertex of this subtree has a given index in the topological sorting of the vertices of the original term.\n",
    "      :param index - subterm index\n",
    "      :param term - λ-term to which the subterm will be replaced\n",
    "      :return: updated λ-term\n",
    "      \"\"\"\n",
    "      if index == 1:\n",
    "        return term\n",
    "\n",
    "      if self.isAtom:\n",
    "        ValueError('index value is incorrect')\n",
    "      elif self.isApplication:\n",
    "        if self._sub.verticesNumber + 1 >= index:\n",
    "          return Application(self._sub.setSubterm(index - 1, term), self._obj)\n",
    "        else:\n",
    "          return Application(self._sub, self._obj.setSubterm(index - self._sub.verticesNumber - 1, term))\n",
    "      else: # self is Abstraction\n",
    "        return Abstraction(self._head, self._body.setSubterm(index - 1, term))\n",
    "\n",
    "    def _updateBoundVariables(self):\n",
    "      \"\"\"return λ-term with updated bound variables\"\"\"\n",
    "      if self.isAtom:\n",
    "        return self\n",
    "      elif self.isApplication:\n",
    "        return Application(self._sub._updateBoundVariables(), self._obj._updateBoundVariables())\n",
    "      else: # self is Abstraction\n",
    "        newVar = Var()\n",
    "        return Abstraction(newVar, self._body._replaceVariable(self._head, Atom(newVar))._updateBoundVariables())\n",
    "\n",
    "    def _removeOuterRedex(self):\n",
    "      \"\"\"apply the betta conversion to the lambda term, removing the outer betta redex\"\"\"\n",
    "      if self.isBetaRedex:\n",
    "        head = self._sub._head\n",
    "        body = self._sub._body\n",
    "        return body._replaceVariable(head, self._obj)\n",
    "      else:\n",
    "        return self\n",
    "\n",
    "    def _replaceVariable(self, var: Var, term):\n",
    "      \"\"\"return λ-term with replaced variable\"\"\"\n",
    "      if self.isAtom:\n",
    "        return term if self._var == var else self\n",
    "      elif self.isApplication:\n",
    "        return Application(self._sub._replaceVariable(var, term), self._obj._replaceVariable(var, term))\n",
    "      else: # self is Abstraction\n",
    "        return Abstraction(self._head, self._body._replaceVariable(var, term))\n",
    "\n",
    "\n",
    "class Atom(Term):\n",
    "    def __init__(self, x: Var):\n",
    "        if isinstance(x, Var):\n",
    "            self._var = x\n",
    "        else:\n",
    "            raise TypeError(\"a variable is waiting\")\n",
    "\n",
    "\n",
    "class Application(Term):\n",
    "    def __init__(self, X : Term, Y : Term):\n",
    "        if isinstance(X, Term) and isinstance(Y, Term):\n",
    "            self._sub = X\n",
    "            self._obj = Y\n",
    "        else:\n",
    "            raise TypeError(\"a term is waiting\")\n",
    "\n",
    "\n",
    "class Abstraction(Term):\n",
    "    def __init__(self, x: Var, X: Term):\n",
    "        if isinstance(x, Var):\n",
    "            if isinstance(X, Term):\n",
    "                self._head = x\n",
    "                self._body = X\n",
    "            else:\n",
    "                raise TypeError(\"a term is waiting\")\n",
    "        else:\n",
    "            raise TypeError(\"a variable is waiting\")\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZmm5XYAPuBU"
   },
   "source": [
    "## Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wBQc8HFUP0s0"
   },
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class OneStepStrategy(ABC):\n",
    "    \n",
    "  @abstractmethod\n",
    "  def redexIndex(self, term: Term, initIndex = 0) -> int:\n",
    "      \"\"\"\n",
    "      :return: index of the vertex of a subterm that has an outer redex. \n",
    "              The index of a vertex is the index of this vertex in the topological sort of the tree vertices.\n",
    "              Indexing starts at 1.\n",
    "      \"\"\"\n",
    "\n",
    "class LeftmostOutermostStrategy(OneStepStrategy):\n",
    "\n",
    "  def redexIndex(self, term: Term, initIndex = 0) -> int:\n",
    "    if term.isAtom or len(term.redexes) == 0:\n",
    "      ValueError('the term does not contain a redex')\n",
    "    elif term.isApplication:\n",
    "      if term.isBetaRedex:\n",
    "        return initIndex + 1\n",
    "      elif len(term._sub.redexes) != 0:\n",
    "        return self.redexIndex(term._sub, initIndex + 1)\n",
    "      else:\n",
    "        return self.redexIndex(term._obj, initIndex + term._sub.verticesNumber + 1)\n",
    "    else: # self is Abstraction\n",
    "      return self.redexIndex(term._body, initIndex + 1)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSPgZKjaYYI_"
   },
   "source": [
    "## Generating lambda terms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSkAkbDMYe4Y",
    "outputId": "1f75c39c-1262-4127-fdfc-7ff9f1a87ddc"
   },
   "source": [
    "import random\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "\n",
    "def genTerm(p: float, vars: List[Var] = []) -> Term:\n",
    "\n",
    "  pVar = (1 - p * p) / 2\n",
    "  pAbs = pVar + p * p\n",
    "\n",
    "  rand = random.random()\n",
    "\n",
    "  if rand < pVar and len(vars) > 0:\n",
    "    index = random.randint(0, len(vars) - 1)\n",
    "    return Atom(vars[index]) \n",
    "  elif rand < pAbs:\n",
    "    head = Var()\n",
    "    return Abstraction(head, genTerm(p, vars + [head]))\n",
    "  else:\n",
    "    return Application(genTerm(p, vars), genTerm(p, vars))\n",
    "\n",
    "def filterTerms(term):\n",
    "  return 500 < term.verticesNumber < 8000 and term.hasNormalForm(LeftmostOutermostStrategy())\n",
    "\n",
    "terms = list(filter(filterTerms, [genTerm(0.5093) for i in range(40)]))\n",
    "\n",
    "if len(terms) != 0:\n",
    "  print(list(map(lambda term: term.verticesNumber, terms)))\n",
    "  print(\"mean number of vertices = {}\".format(sum(map(lambda term: term.verticesNumber, terms)) / len(terms)))\n",
    "  print(\"max number of vertices = {}\".format(max(map(lambda term: term.verticesNumber, terms))))\n",
    "\n",
    "  countRedexes = list(map(lambda term: len(term.redexes), terms))\n",
    "\n",
    "  print(countRedexes)\n",
    "  print(\"mean number of redexes = {}\".format(sum(countRedexes) / len(countRedexes)))\n",
    "  print(\"max number of redexes = {}\".format(max(countRedexes)))\n",
    "\n",
    "for term in terms:\n",
    "  t, count = term.normalize(LeftmostOutermostStrategy())\n",
    "  print(count)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2448, 1218]\n",
      "mean number of vertices = 1833.0\n",
      "max number of vertices = 2448\n",
      "[257, 112]\n",
      "mean number of redexes = 184.5\n",
      "max number of redexes = 257\n",
      "19\n",
      "1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qveFjH3giax4"
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNtm7Vw5iiiL",
    "outputId": "2509ecf1-7432-4647-c4f0-03361413469d"
   },
   "source": [
    "x, y, z = Var(), Var(), Var()\n",
    "X, Z = Atom(x), Atom(z)\n",
    "XXX = Application(Application(X, X), X)\n",
    "XZ = Application(X, Z)\n",
    "T = Application(Abstraction(x, XXX),\n",
    "                Abstraction(x, Application(Abstraction(y, Z),\n",
    "                                           XZ\n",
    "                                          ))\n",
    "               )\n",
    "\n",
    "print(T)\n",
    "for var, item in T._vars.items():\n",
    "    print(\"\\t{}\".format(var), end=\": \")\n",
    "    print(item)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((fun v[230205] => ((v[230205] v[230205]) v[230205])) (fun v[230205] => ((fun v[230206] => v[230207]) (v[230205] v[230207]))))\n",
      "\tv[230205]: {'free': 0, 'bound': 4}\n",
      "\tv[230207]: {'free': 2, 'bound': 0}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k_y4wapyittq"
   },
   "source": [
    "x, y, z, w, v = Var(), Var(), Var(), Var(), Var()\n",
    "# (λx.(λy.( ((λz.(y z)) ((λw.w) x)) v )))\n",
    "lambdaTerm = Abstraction(x,\n",
    "                        Abstraction(y,\n",
    "                                    Application(\n",
    "                                        Application(\n",
    "                                            Abstraction(z, Application(Atom(y), Atom(z))),\n",
    "                                            Application(Abstraction(w, Atom(w)), Atom(w))),\n",
    "                                        Atom(v))))\n",
    "\n",
    "def testTerm():\n",
    "  assert(len(lambdaTerm.redexes) == 2)\n",
    "  assert(lambdaTerm.verticesNumber == 13)\n",
    "\n",
    "  subterm = Application(Atom(y), Atom(z))\n",
    "  assert(lambdaTerm.subterm(1) == lambdaTerm)\n",
    "  assert(lambdaTerm.subterm(6) == subterm)\n",
    "  assert(lambdaTerm.setSubterm(1, subterm) == subterm)\n",
    "\n",
    "  assert(lambdaTerm._updateBoundVariables().verticesNumber == lambdaTerm.verticesNumber)\n",
    "  assert(len(lambdaTerm._updateBoundVariables().redexes) == len(lambdaTerm.redexes))\n",
    "\n",
    "  strategy = LeftmostOutermostStrategy()\n",
    "  assert(len(lambdaTerm._betaConversion(strategy).redexes) == 1)\n",
    "  assert(lambdaTerm._betaConversion(strategy).verticesNumber == 10)\n",
    "\n",
    "  assert(len(lambdaTerm.normalize(strategy)[0].redexes) == 0)\n",
    "  assert(lambdaTerm.normalize(strategy)[1] == 2)\n",
    "\n",
    "\n",
    "def testStrategy():\n",
    "  strategy = LeftmostOutermostStrategy()\n",
    "  assert(strategy.redexIndex(lambdaTerm) == 4)\n",
    "\n",
    "testTerm()\n",
    "testStrategy()"
   ],
   "execution_count": 11,
   "outputs": []
  }
 ]
}